{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference EfficientNet Keras - Regression\n",
    "\n",
    "---\n",
    "\n",
    "This is an inference kernel. You can find the training one **[HERE](https://www.kaggle.com/raimonds1993/aptos19-efficientnet-keras-regression)**.\n",
    "\n",
    "### If you enjoyed the kernel, <span style=\"color:red\">please upvote :)</span>.\n",
    "\n",
    "### Credits\n",
    "\n",
    "- [Efficient Net weights](https://www.kaggle.com/ratthachat/efficientnet-keras-weights-b0b5), by **Neuron Engineer**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "73086574-7f5c-474b-a46b-815e93bcfadd",
    "_uuid": "abcabfe4-885f-48cd-bd62-fd22394f27ae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['efficientnet-keras-weights-b0b5', 'efficientnet-keras-aptos', 'aptos2019-blindness-detection', 'kerasefficientnetsmaster']\n",
      "(1928, 1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from keras import layers\n",
    "from keras.callbacks import Callback, ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import cohen_kappa_score, accuracy_score\n",
    "import scipy\n",
    "from tqdm import tqdm\n",
    "print(os.listdir('../input'))\n",
    "\n",
    "\n",
    "im_size = 224\n",
    "\n",
    "test_df = pd.read_csv('../input/aptos2019-blindness-detection/test.csv')\n",
    "\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility functions\n",
    "def crop_image1(img,tol=7):\n",
    "    # img is image data\n",
    "    # tol  is tolerance\n",
    "        \n",
    "    mask = img>tol\n",
    "    return img[np.ix_(mask.any(1),mask.any(0))]\n",
    "\n",
    "def crop_image_from_gray(img,tol=7):\n",
    "    if img.ndim ==2:\n",
    "        mask = img>tol\n",
    "        return img[np.ix_(mask.any(1),mask.any(0))]\n",
    "    elif img.ndim==3:\n",
    "        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        mask = gray_img>tol\n",
    "        \n",
    "        check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n",
    "        if (check_shape == 0): # image is too dark so that we crop out everything,\n",
    "            return img # return original image\n",
    "        else:\n",
    "            img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n",
    "            img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n",
    "            img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n",
    "            img = np.stack([img1,img2,img3],axis=-1)\n",
    "        return img\n",
    "\n",
    "\n",
    "def preprocess_image(image_path, desired_size=224):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = crop_image_from_gray(img)\n",
    "    img = cv2.resize(img, (desired_size,desired_size))\n",
    "    img = cv2.addWeighted(img,4,cv2.GaussianBlur(img, (0,0), desired_size/30) ,-4 ,128)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset correctly processed\n"
     ]
    }
   ],
   "source": [
    "N = test_df.shape[0]\n",
    "x_test = np.empty((N, im_size, im_size, 3), dtype=np.uint8)\n",
    "\n",
    "try:\n",
    "    for i, image_id in enumerate(test_df['id_code']):\n",
    "        x_test[i, :, :, :] = preprocess_image(\n",
    "            f'../input/aptos2019-blindness-detection/test_images/{image_id}.png',\n",
    "            desired_size=im_size\n",
    "        )\n",
    "    print('Test dataset correctly processed')\n",
    "except:\n",
    "    print('Test dataset NOT processed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model: EffNetB5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['optimize.py', 'config.py', 'custom_objects.py', '__init__.py', 'efficientnet.py']\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "model_1 (Model)              (None, 7, 7, 2048)        28513520  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 7, 7, 2048)        0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 7, 7, 2048)        4196352   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 7, 7, 2048)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 32,711,921\n",
      "Trainable params: 32,539,185\n",
      "Non-trainable params: 172,736\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(\"../input/kerasefficientnetsmaster/keras-efficientnets-master/keras-efficientnets-master/keras_efficientnets\"))\n",
    "sys.path.append(os.path.abspath('../input/kerasefficientnetsmaster/keras-efficientnets-master/keras-efficientnets-master/'))\n",
    "from keras_efficientnets import EfficientNetB5\n",
    "effnet = EfficientNetB5(input_shape=(im_size,im_size,3),\n",
    "                        weights=sys.path.append(os.path.abspath('../input/efficientnet-keras-weights-b0b5/efficientnet-b5_imagenet_1000_notop.h5')),\n",
    "                        include_top=False)\n",
    "\n",
    "\n",
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(effnet)\n",
    "    model.add(layers.Dropout(0.25))\n",
    "    model.add(layers.Dense(2048))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(1, activation='linear'))\n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "model.load_weights('../input/efficientnet-keras-aptos/model.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    42.7905\n",
      "3    27.5415\n",
      "0    19.1909\n",
      "1     8.1950\n",
      "4     2.2822\n",
      "Name: diagnosis, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "y_test = model.predict(x_test)\n",
    "\n",
    "\n",
    "coef = [0.5, 1.5, 2.5, 3.5]\n",
    "\n",
    "# Optimized on validation set\n",
    "#coef = [0.5370942, 1.51580731, 2.61728832, 3.37044039]\n",
    "\n",
    "for i, pred in enumerate(y_test):\n",
    "    if pred < coef[0]:\n",
    "        y_test[i] = 0\n",
    "    elif pred >= coef[0] and pred < coef[1]:\n",
    "        y_test[i] = 1\n",
    "    elif pred >= coef[1] and pred < coef[2]:\n",
    "        y_test[i] = 2\n",
    "    elif pred >= coef[2] and pred < coef[3]:\n",
    "        y_test[i] = 3\n",
    "    else:\n",
    "        y_test[i] = 4\n",
    "\n",
    "test_df['diagnosis'] = y_test.astype(int)\n",
    "test_df.to_csv('submission.csv',index=False)\n",
    "\n",
    "print(round(test_df.diagnosis.value_counts()/len(test_df)*100,4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
